---
layout: default
title:  "Stupid things that clients say"
date:   2021-12-14 00:00:00
categories: diary
image:
    path: spicyMemes/facePalm.jpg
---
<h1>Stupid things that clients say</h1>

I get it, security is not understood by everyone. I don't expect it to be. The IT world is quite diverse and complex, no one expects you to know all the details of every working component. I don't know them either. The issues arise when you are trying to justify some aspects when facing concrete evidence which contradicts your ideas or when you are invoking some lame ass excuse for why your product is not secure. Well, gather round folks, today we'll go through some stories of what stupid excuses clients make. Remember, it's all a joke (just like the way you treat the security of your assets) so if you feel hurt, feel free to DM me on twitter for some ointment.

<center><img src="/spicyMemes/test.gif" alt="test" style="float:center"></center>

Through the years of working as a penetration tester, you hear a lot of funny things or excuses. Here are some of the best lines I've heard so far:

**SQL injections are not a security issue**: While testing a web application, an SQL injection issue was identified. For those that don't know, in a very broad term, an SQL injection is when the attacker (user) is able to directly alter the SQL statement that is being executed in the back end. This can sometimes lead to full access of confidential data or even code execution. In this particular case, the vulnerability would allow for extraction of usernames and some PII data. The issue was documented and forwarded to the client. Upon analysis, the client came back with the answer: *This is just an application error and not a vulnerability*. The reasoning behind their statement was that if a user tries to inject some SQL statement and errors are noted, further attempts will be stopped and the attack vector will not be pursued. Excuse me? All security issues are either application, configuration or human error. Do we really care how we label it? I would have loved to pursue this discussion and ask what their views of security issues are? At what point do errors transition in security vulnerabilities?  

**Why would you care about other usernames?**: Gotta admit, this is a somewhat lower impact issue indeed. Good old username enumeration. The client was really baffled on why anyone would try to enumerate users within the application. The reasoning this time being: *You already know your username, why would you care about others?* In my opinion, having the username is half the battle (or close to half). For example password bruteforce attacks rely on having a valid list of usernames. Furthermore, if other issues are surfaced (such as access control vulnerabilities), knowing other usernames might allow you to perform a targeted lateral movement within the application.

**But that is illegal**: Taking things up a notch. During an assessment, we identified that the application was really lacking input filtering or output encoding measures. This ended up with the target being plagued by Cross-Site Scripting vulnerabilities. Even worse, the cookies were not protected with the HttpOnly flag so capturing them was quite a breeze. In simple terms: shit was on fire yo! An attacker could easily get a hold of other users' sessions and impersonate them. Given this behaviour, we would have normally documented the findings as High (on a Low, Medium, High scale), but since there were other issues that were even worse (think of remote code execution) we filed the XSS ones as Medium. Then, the official response came from the client: *Our users would never try to mount such attacks as they are accepting a "terms of service" agreement. Furthermore, such actions are illegal so there will be consequences if they do it.* Riiight. Somebody call the cyber police guys! Look, I'm not saying that such attacks are not illegal, but, why do you need a penetration test then if you just rely on the long arm of the law to protect you? It would be like saying that you don't need to lock your door since it's illegal for others to enter your house anyway. Don't you want to take some extra measures to protect yourself? Threat actors demonstrated a long time ago that they don't care about security boundaries so try to be proactive about these aspects will ya? Anyway, they wanted the issue lowered to a Low severity (guessing if the scale went even lower they would have picked that). I still wonder if those issues were ever addressed... :)

<center><img src="/spicyMemes/theLaw.gif" alt="JudgeDredd" style="float:center"></center>

**We just deployed that change and it was a temporary fix**: Strap your seatbelts y'all. We're going with the cream of the crop here. While testing a web application that handled a LOT of PII stuff we achieved code execution on it. The biggest surprise however was waiting around the corner. The context in which code was being executed was that of a domain administrator. Say what? Yes, you read it right, a web application was running code under a user that was a domain administrator. Not some IIS user that had impersonation tokens available, no. Straight up DA. This ultimately led to access over PII but all the servers, employees and everything else inside that network. A penetration tester's dream and ultimate goal, all with a simple code execution vulnerability. The behaviour was immediately highlighted to the client with the recommendation of addressing the issue as soon as possible. I'd love to tell you that the issue was solved overnight. Spoiler alert: it wasn't. Instead, the client spent a lot of time justifying why the user was running as DA. Apparently it was a "quick and dirty patch" to an issue they were experiencing. A few things came to mind when I heard this. First, these workarounds have an awful tendency to turn into legacy code. Second, I really wondered for how long that patch was in place. Do you think that if real attackers exploit the same issue, they will wait around for you to drop the latest fix that is secure enough? Security is not something that should be only taken into consideration every now and then. You should make sure that your defenses are working 24/7.

There are more, such as *we don't need network segmentation* or *we decided we need a lot of domain user admins for X task* but I'll keep those for a second part. The main reason why I noticed these excuses are being brought up, is that they want the rating of the issues lowered. Just to have a better looking report to share with the stakeholders or whatever other party the findings are shared with. It is not uncommon for a client to ask for multiple versions of the same report. Even had an event of one person asking for a "special" report that only contained the low issues that were identified.

Just to also play the devil's advocate, it could be that the vulnerabilities were sometimes not documented well enough. As a pentester, you should always try to document your findings and highlight the impact that they could have. The best example for this would be an alert box for Cross-Site Scripting issues will most likely leave customers (especially the ones that did not have to deal with the security field that much) scratching their head regarding what the actual vulnerability is. Try to elevate it a bit, show what you can do with it (can you capture cookies? can you do a session pivoting attack?).

**Key takeaways:**
- As a penetration tester always try to best outline the impact that an issue has (I know time is limited and fancy proof of concepts take time)
- As a client, you are better off spending time on addressing the issues than on coming up with excuses on why they are there. The penetration testing team really does not care about that.
- Do not rely on silly things like chance or legality of actions. Best way to think of a security incident is "when" will it occur rather than "if".
- If it happens, accept the fact that your application is not that secure. Trying to mask any shortcoming will eventually come back and bite yo ass.

